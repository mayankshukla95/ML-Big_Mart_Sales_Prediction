# -*- coding: utf-8 -*-
"""Big_Mart_Sales_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16RVZEaWN_Unf4gYonG58OFCnAz-_ehMH
"""

# To Upload files.
"""from google.colab import files
uploaded = files.upload()"""

#Importing all libraries
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import seaborn as sns

import plotly.express as px

# Read the dataset
Train=pd.read_csv("/content/train_v9rqX0R.csv")
Test=pd.read_csv("/content/test_AbJTz2l.csv")

# Shape of Data
Train.shape, Test.shape

# Concating Data Adding source Column to separate the Data After EDA

Train['source']='Train'
Test['source']='Test'

df = pd.concat([Train,Test], ignore_index=True)
df.shape

"""# **Data Exploration And Feature Engineering**"""

df.head()

# Info About DataFrame
df.info()

# Checking The Null Values
df.isnull().sum()

"""**Note** :-  We Know That In Our Test Data We Don't Have Item_Outlet_Sales Value, This Is Why It Is Showing 5681 Null Value.

***Filling Missing Values in Item_Weight***
"""

# Boxplot To Check Outliers In Item_Weight Feature from DataFrame

px.box(df,x="Item_Weight")

"""**Note :-** We Don't Have Outliers,So We Move On With The Mean Value."""

# Mean of Item_Weight

mean_item_weight=round(df["Item_Weight"].mean(),2)
print(f"Mean Of Item Weight =",mean_item_weight)

# Filling The Not Available Value In Item_Weight
df["Item_Weight"] = df["Item_Weight"].fillna(mean_item_weight)

# Checking For Missing(Null) Value in Item_Weight
df["Item_Weight"].isnull().sum()

"""***Filling Missing Values in Outlet_Size***

Treatment Of Categorical Feature Missing Value
"""

# Checking Unique Values in Outlet_Size
df["Outlet_Size"].unique()

# Value Count of Outlet_Size
df["Outlet_Size"].value_counts()

# Null Values
print(f"Null Values in Outlet_Size :",df["Outlet_Size"].isnull().sum())

# Mode of Outlet_Size

mode_Outlet_Size=df["Outlet_Size"].mode()[0]
print(f"Mode Of Outlet_Size =",mode_Outlet_Size)

# Filling The Not Available Value In Outlet_Size
df["Outlet_Size"] = df["Outlet_Size"].fillna(mode_Outlet_Size)

# Checking For Missing(NUll) Value in Outlet_Size After Filling Missing(Null) Values
df["Outlet_Size"].isnull().sum()

# Again Checking For Missing(NUll) Value in Whole Data Frame
df.isnull().sum()

# Checking Number Of Unique Values And Data Type In Our Columns

for col in df.iloc[:,0:20].columns:
  print(col, ":",df[col].nunique(),",","Dtype",":",df[col].dtype)

# Analysis Of Item_Identifier
for i in range(0,20):
  print(df['Item_Identifier'].unique()[i],end=" ")

"""**Note :-** In Item_Identifier It Is Object Data Type Also It Has 1559 Unique Value,
But if you can notice all the values have Three Distinct Identifier -> FD, DR, NC.
"""

# FD -> Food Item
# DR -> Drinkable Item
# NC -> Non-Consumabale Item

# Converting Into These Three Identifier
df['Item_Identifier']=df['Item_Identifier'].str.slice(0,2)
df['Item_Identifier'].head()

# Violin Plot For Item_Fat_Content and Item_Outlet_Sales

plt.figure(figsize=(10,3))
sns.violinplot(data=df, x='Item_Fat_Content', y='Item_Outlet_Sales', inner='quartile')

# Unique Value In Item_Fat_Content.

df['Item_Fat_Content'].unique()

"""**Note** :-  Item_Fat_Content Has 2 Unique Value, It Just Written In Wrong way At The Time Of Data Entry."""

# Replacing The Item_Fat_Content With Right Value, And Checkin Unique Value Again.

df["Item_Fat_Content"]=df['Item_Fat_Content'].replace({'Regular':'Regular','reg':'Regular','Low Fat':'Low Fat','low fat':'Low Fat','LF':'Low Fat'})
df["Item_Fat_Content"].unique()

# Violin Plot For Item_Type and Item_Outlet_Sales

plt.figure(figsize=(25,5))
sns.violinplot(data=df, x='Item_Type', y='Item_Outlet_Sales', inner='quartile')

# Violin Plot For Outlet_Identifier and Item_Outlet_Sales

plt.figure(figsize=(10,2))
sns.violinplot(data=df, x='Outlet_Identifier', y='Item_Outlet_Sales', inner='quartile')

# Violin Plot For Outlet_Size and Item_Outlet_Sales

plt.figure(figsize=(10,2))
sns.violinplot(data=df, x='Outlet_Size', y='Item_Outlet_Sales', inner='quartile')

# Total Sales Amount as Per Outlet_Size

print(f"Outlet_Size_Medium :",round(df[df["Outlet_Size"]=="Medium"]['Item_Outlet_Sales'].sum(),2))
print(f"Outlet_Size_High :   ",round(df[df["Outlet_Size"]=="High"]['Item_Outlet_Sales'].sum(),2))
print(f"Outlet_Size_Small :  ",round(df[df["Outlet_Size"]=="Small"]['Item_Outlet_Sales'].sum(),2))

# Violin Plot For Outlet_Type and Item_Outlet_Sales

plt.figure(figsize=(10,2))
sns.violinplot(data=df, x='Outlet_Type', y='Item_Outlet_Sales', inner='quartile')

# Scatter Plot B/t Item_MRP and Item_Outlet_Sales
fig = px.scatter(df,x='Item_MRP',y='Item_Outlet_Sales',color='Outlet_Type')

fig.update_layout(width=1200, height=400)
fig.show()

"""**Note :-** Item_MRP Comes Under Continuous Variable, So We Go for Discretization.


***Discretization***
"""

df["Item_MRP"].describe()

# Binning item_MRP
# Item_MRP -> (0-65) :A, (65-135) :B, (135-205) :C, (135-205) :D

df["Item_MRP2"]=pd.cut(df["Item_MRP"],
                          bins=[0,65,135,205,300],
                          labels=['A','B','C','D'])

# Scatter Plot B/t Item_Weight and Item_Outlet_Sales

plt.figure(figsize=(10,2))
sns.scatterplot(data=df, x='Item_Weight', y='Item_Outlet_Sales')

# Scatter Plot B/t Item_Visibility and Item_Outlet_Sales

plt.figure(figsize=(10,3))
sns.scatterplot(data=df, x='Item_Visibility', y='Item_Outlet_Sales')

# Value Count of 0 in Item_Visibility.
df['Item_Visibility'].value_counts()[0.00]

"""**Note :-** Item Visibility Has So Many Zeros [0] In It We're Going To Treat Them As A Null Value."""

# In Item_Visibility Replacing 0 With NaN To Treat Them As a Null Value.

df["Item_Visibility"]=np.where(df["Item_Visibility"]==0,'NaN',df["Item_Visibility"]).astype(float)
df["Item_Visibility"].head()

# Filling the Missing(Null) Value In Item_Visibility.

df["Item_Visibility"]=df["Item_Visibility"].fillna(df["Item_Visibility"].mean())
df["Item_Visibility"].head()

# Making New Feature Named Outlet_Establishment_Age for More Interpritability.

df["Outlet_Establishment_Age"]= 2013-df["Outlet_Establishment_Year"]
df["Outlet_Establishment_Age"].head()

# Making New Feature Price_Per_Item for Enhancement of Model Learning.

df["Price_Per_Item"] = df['Item_MRP']/df['Item_Weight']
df["Price_Per_Item"].head(1)

df.head(1)

# Checking Data Type For Encoding

for col_dtype in df.iloc[:,0:20].columns:
  print(col_dtype, ":",df[col_dtype].dtype)

# Commented out IPython magic to ensure Python compatibility.
# # Applying One-Hot Encoding On Categorical Features
# 
# %%capture
# !pip install category_encoders
# from category_encoders import OneHotEncoder # Importing OneHotEncoder
# 
# categorical_features = ['Item_Identifier', 'Item_Fat_Content', 'Item_Type',
#                         'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type',
#                         'Outlet_Type','Item_MRP2']
# 
# encoder = OneHotEncoder(cols=categorical_features, handle_unknown='ignore') # Creating Encoder Instance
# df = encoder.fit_transform(df)

# Extracting the Original DataFrames

train=df[df["source"]=='Train'].copy()
train.reset_index(drop=True, inplace=True)

test=df[df["source"]=='Test'].copy()
test.reset_index(drop=True, inplace=True)

# Droping Source Columns

train.drop(columns=['source'],inplace=True)
test.drop(columns=['source'],inplace=True)

# Separating The Features As Per Target Variable("Item_Outlet_Sales")

x_train = train.drop(['Item_Outlet_Sales','Outlet_Establishment_Year'],axis=1)  # Independent Variable (Taking As a DataFrame)
y_train = train['Item_Outlet_Sales']  # Dependent Variable Taking As a Series

"""***Splitting Data For Traning And Testing Sets.***"""

# Split the data into traning and testing sets
from sklearn.model_selection import train_test_split
train_x, test_x, train_y, test_y = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

"""# **Machine Learning Models And Evaluation**

***Linear Regression***
"""

# Initialize a Linear Regression
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(train_x,train_y)

# predict on test data
y_pred = model.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

"""***Decision Tree Regression***"""

# Initialize a Decision Tree Regression
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor(random_state=42)
model.fit(train_x,train_y)

# predict on test data
y_pred = model.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

"""***Random Forest Regression***"""

# Initialize a Random Forest Regression
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(train_x,train_y)

# predict on test data
y_pred = model.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

"""***Gradient Boosting Regression***"""

# Initialize a Gradient Boosting Regression
from sklearn.ensemble import GradientBoostingRegressor
model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
model.fit(train_x,train_y)

# predict on test data
y_pred = model.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

"""***XGBoost Regression***"""

# Initialize a XGBoost Regression
from xgboost import XGBRegressor
model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, objective='reg:squarederror')
model.fit(train_x,train_y)

# predict on test data
y_pred = model.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

"""***LightGBM Regression***"""

# Initialize a LightGBM Regression
import lightgbm as lgb
model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
model.fit(train_x,train_y)

# predict on test data
y_pred = model.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

"""***CatBoost Regression***"""

# Commented out IPython magic to ensure Python compatibility.
# # Installing CatBoost
# %%capture
# !pip install catboost

# Initialize a CatBoost Regression
from catboost import CatBoostRegressor
model = CatBoostRegressor(iterations=100, learning_rate=0.1, random_state=42, verbose=0)
model.fit(train_x,train_y)

# predict on test data
y_pred = model.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

"""# **Best Model Perfonance :- CatBoost Regression**"""

# Initialize the CatBoost Regression
from catboost import CatBoostRegressor
model_cat = CatBoostRegressor(iterations=100, learning_rate=0.1, random_state=42, verbose=0)
model_cat.fit(train_x,train_y)

# predict on test data
y_pred = model_cat.predict(test_x)

# Evaluation
from sklearn.metrics import mean_squared_error
print("Root Mean Squared Error : ", np.sqrt(mean_squared_error(test_y, y_pred)))

# Fitting Testing Data In Model For Pridicting Item_Outlet_Sales

test_new = test.drop(['Item_Outlet_Sales','Outlet_Establishment_Year'],axis=1)
y_pred_test = model_cat.predict(test_new)

# Making New DataFrame For Submission File.

submit=pd.DataFrame({'Item_Identifier' : Test['Item_Identifier'],
                     'Outlet_Identifier' : Test['Outlet_Identifier']})

# Min Value Of Item_Output_Sales Feature

train["Item_Outlet_Sales"].min()

# Extracting Submission File

y_pred_test[y_pred_test<33]=33
submit['Item_Outlet_Sales']=y_pred_test
submit.to_csv('Final_Submission.csv',index=False)
submit.head()

submit.isnull().sum()